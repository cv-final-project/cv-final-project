{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "nose_classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wHtJWO6jUDa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Displays a progress bar\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
        "from torch.utils.data.sampler import WeightedRandomSampler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-vqrISmTYj"
      },
      "source": [
        "# if torch.cuda.is_available():\n",
        "#     print(\"Using the GPU. You are good to go!\")\n",
        "#     device = torch.device('cuda:0')\n",
        "# else:\n",
        "#     raise Exception(\"WARNING: Could not find GPU! Using CPU only. \\\n",
        "# To enable GPU, please to go Edit > Notebook Settings > Hardware \\\n",
        "# Accelerator and select GPU.\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQphnO1XqS5F",
        "outputId": "ba0dd40f-937a-4221-c828-fbf72b51a696"
      },
      "source": [
        "! rm -rf sample_data/\n",
        "!git clone https://eecs442finalproject:eecs442isgreat@github.com/cv-final-project/cv-final-project.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cv-final-project'...\n",
            "remote: Enumerating objects: 3144, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 3144 (delta 21), reused 2 (delta 0), pack-reused 3109\u001b[K\n",
            "Receiving objects: 100% (3144/3144), 1.04 GiB | 43.99 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Checking out files: 100% (3047/3047), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEnMl58lY9ew"
      },
      "source": [
        "########\n",
        "class_d = {\n",
        "    'nose':['chin/','mouth_chin/','no_mask/'],\n",
        "    'no_nose':['mouth_nose/','mouth_nose_chin/']\n",
        "}\n",
        "########\n",
        "os.mkdir('org_data')\n",
        "for class_ in class_d:\n",
        "  class_d[class_] = ['cv-final-project/data/train/'+x for x in class_d[class_]]\n",
        "  if not os.path.isdir(class_):\n",
        "    os.mkdir('org_data/'+class_)\n",
        "  for folder_ in class_d[class_]:\n",
        "    folder = os.listdir(folder_)\n",
        "    for file in folder:\n",
        "      shutil.copy2(folder_+file, 'org_data/'+class_)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isUjKiqDlgcR"
      },
      "source": [
        "! rm -rf cv-final-project/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq85Qd3XmOzx",
        "outputId": "ab469c33-94d1-4146-8300-80f4b7ce7ead"
      },
      "source": [
        "len(os.listdir('org_data/no_nose')), len(os.listdir('org_data/nose'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(895, 1528)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlPd_CWFrW0Y"
      },
      "source": [
        "def get_class_weights(classes):\n",
        "  weights = [len(os.listdir('org_data/'+class_)) for class_ in classes]\n",
        "  weights = [x/min(weights) for x in weights]\n",
        "  return weights\n",
        "def get_loader(data, classes, BATCH_SIZE):\n",
        "  weights = get_class_weights(classes)\n",
        "  weights_per_sample = [0 for i in range(len(data))]\n",
        "  for idx, (sample, target) in enumerate(data):\n",
        "    weights_per_sample[idx] = weights[target]\n",
        "  wrs = WeightedRandomSampler(weights=weights_per_sample, \n",
        "                              num_samples=len(weights_per_sample),\n",
        "                              replacement=True)\n",
        "  return DataLoader(data, batch_size=BATCH_SIZE, sampler=wrs)\n",
        "def load_data_balanced(classes, BATCH_SIZE):\n",
        "  grayscale_resize = transforms.Compose([\n",
        "      transforms.Grayscale(num_output_channels=1),\n",
        "      transforms.Resize((100, 100)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "  train_data = datasets.ImageFolder('org_data', transform=grayscale_resize)\n",
        "  train_size = int(0.8*len(train_data))\n",
        "  val_size = len(train_data) - train_size\n",
        "  train_data, val_data = random_split(train_data, \n",
        "                                      [train_size, val_size],\n",
        "                                      generator=torch.Generator().manual_seed(42))\n",
        "  print(\"Getting train loader...\")\n",
        "  train_loader = get_loader(train_data, classes, BATCH_SIZE)\n",
        "  print(\"Getting val loader...\")\n",
        "  val_loader = get_loader(val_data, classes, BATCH_SIZE)\n",
        "  return train_loader, val_loader\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlukVglwY8Z2",
        "outputId": "7f297ce6-4d85-40bb-f5b9-33590e9d4b93"
      },
      "source": [
        "###########HYPERPARAMETERS###########\n",
        "BATCH_SIZE = 8\n",
        "#####################################\n",
        "train_loader, val_loader = load_data_balanced(class_d.keys(), BATCH_SIZE)\n",
        "print(train_loader, val_loader)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting train loader...\n",
            "Getting val loader...\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f3468949ed0> <torch.utils.data.dataloader.DataLoader object at 0x7f341659ef50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdy-vbHOTS6N",
        "outputId": "6131924c-8144-4f56-b789-2c6f1088c138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    ##############################################################################\n",
        "    # TODO: Design your own network, define layers here.                          #\n",
        "    # Here We provide a sample of two-layer fc network from HW4 Part3.           #\n",
        "    # Your solution, however, should contain convolutional layers.               #\n",
        "    # Refer to PyTorch documentations of torch.nn to pick your layers.           #\n",
        "    # (https://pytorch.org/docs/stable/nn.html)                                  #\n",
        "    # Some common choices: Linear, Conv2d, ReLU, MaxPool2d, AvgPool2d, Dropout   #\n",
        "    # If you have many layers, use nn.Sequential() to simplify your code         #\n",
        "    ##############################################################################\n",
        "    self.in_dim = 1\n",
        "    self.mid_layer_params = 32\n",
        "    self.num_classes = 2\n",
        "    self.cnn_layers_max = nn.Sequential(\n",
        "        # Defining a 2D convolution layer\n",
        "        nn.Conv2d(1, self.mid_layer_params, kernel_size=3),\n",
        "        nn.BatchNorm2d(self.mid_layer_params),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.cnn_layers_avg = nn.Sequential(\n",
        "        nn.Conv2d(self.mid_layer_params, self.mid_layer_params, kernel_size=3),\n",
        "        nn.BatchNorm2d(self.mid_layer_params),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.cnn_layers_max_2 = nn.Sequential(\n",
        "        nn.Conv2d(self.mid_layer_params, self.mid_layer_params, kernel_size=3),\n",
        "        nn.BatchNorm2d(self.mid_layer_params),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.linear_layers = nn.Sequential(\n",
        "        # nn.Linear(self.mid_layer_params, 2)\n",
        "        nn.Linear(self.mid_layer_params, self.num_classes)\n",
        "    )\n",
        "    \n",
        "    ##############################################################################\n",
        "    #                             END OF YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "\n",
        "  def forward(self,x):\n",
        "    ##############################################################################\n",
        "    # TODO: Design your own network, implement forward pass here                 # \n",
        "    ##############################################################################\n",
        "    x = self.cnn_layers_max(x)\n",
        "    x = self.cnn_layers_avg(x)\n",
        "    x = self.cnn_layers_max_2(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    # x = self.linear_layers(x)\n",
        "    return x\n",
        "    ##############################################################################\n",
        "    #                             END OF YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "\n",
        "model = Network().to(device)\n",
        "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
        "print('Your network:')\n",
        "print(summary(model, (1,100,100))) # visualize your model\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Modify the lines below to experiment with different optimizers,      #\n",
        "# parameters (such as learning rate) and number of epochs.                   #\n",
        "##############################################################################\n",
        "# Set up optimization hyperparameters\n",
        "learning_rate = 1e-2\n",
        "weight_decay = 1e-4\n",
        "num_epoch = 10  # TODO: Choose an appropriate number of training epochs\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate,\n",
        "                       weight_decay=weight_decay)\n",
        "##############################################################################\n",
        "#                             END OF YOUR CODE                               #\n",
        "##############################################################################"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ebd0d06845c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m##############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Specify the loss layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your network:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0aIwScpyGve"
      },
      "source": [
        "#External References used\n",
        "## https://discuss.pytorch.org/t/iterating-through-imagefolder-for-sample-target/82291/2\n",
        "## ^how to iterate through ImageFolder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvMCyEI_VfXh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}